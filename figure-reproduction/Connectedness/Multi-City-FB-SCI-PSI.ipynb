{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preamble for most code and jupyter notebooks\n",
    "@author: tobinsouth\n",
    "@notebook date: May 19, 2023\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, matplotlib as mpl, seaborn as sns\n",
    "import math, string, re, pickle, json, os, sys, datetime, itertools, glob\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from tueplots import bundles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghns = ['geohash9','geohash8','geohash7','geohash6','geohash5','geohash4','geohash3']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Cuebiq PSI Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zip_to_zip_psi(file):\n",
    "    zip_to_zip_overlap_means_df = pd.read_csv(file)\n",
    "    zip_to_zip_overlap_means_df['zip1'] = zip_to_zip_overlap_means_df['zip1'].astype(str).str.zfill(5)\n",
    "    zip_to_zip_overlap_means_df['zip2'] = zip_to_zip_overlap_means_df['zip2'].astype(str).str.zfill(5)\n",
    "    # Log geohashs\n",
    "    for ghn in ghns:\n",
    "        zip_to_zip_overlap_means_df['log_'+ghn] = np.log1p(zip_to_zip_overlap_means_df[ghn])\n",
    "    return zip_to_zip_overlap_means_df\n",
    "\n",
    "zip2zipPIS = {}\n",
    "for file in glob.glob('results/zip_to_zip_overlap_means_df*.csv'):\n",
    "    zip2zipPIS[file.split(\".\")[0][-5:]] = load_zip_to_zip_psi(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zips_with_data = set()\n",
    "for df in zip2zipPIS.values():\n",
    "    all_zips_with_data = all_zips_with_data | set(df['zip1']) | set(df['zip2'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in FB Social Connectendness Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  us-zip-code-us-zip-code-fb-social-connectedness-index-october-2021.zip\n",
      "replace zcta_zcta_shard5.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!cd data/fb-sci && unzip us-zip-code-us-zip-code-fb-social-connectedness-index-october-2021.zip && A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:28<00:00, 56.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the zipfile `us-zip-code-us-zip-code-fb-social-connectedness-index-october-2021.zip` to access each file titled 'zcta_zcta_shardN.tsv`. \n",
    "# Each file contains the social connectedness index for zipcodes in the US. Keep only those zipcodes that are in the `all_zips_with_data` set.\n",
    "\n",
    "# Read in the social connectedness index for each zipcode\n",
    "all_social_connectedness = []\n",
    "import glob\n",
    "for file in tqdm(glob.glob('data/fb-sci/zcta_zcta_shard*.tsv')):\n",
    "    social_connectedness = pd.read_csv(file, sep='\\t')\n",
    "    social_connectedness['user_loc'] = social_connectedness['user_loc'].astype(str).str.zfill(5)\n",
    "    social_connectedness['fr_loc'] = social_connectedness['fr_loc'].astype(str).str.zfill(5)    \n",
    "    social_connectedness = social_connectedness[social_connectedness['user_loc'].isin(all_zips_with_data) & social_connectedness['fr_loc'].isin(all_zips_with_data)]\n",
    "\n",
    "    all_social_connectedness.append(social_connectedness)\n",
    "social_connectedness = pd.concat([sc for sc in all_social_connectedness if len(sc) > 0])\n",
    "social_connectedness.rename(columns={'user_loc': 'zip1', 'fr_loc': 'zip2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_connectedness['log_sci'] = np.log1p(social_connectedness['scaled_sci'])\n",
    "# social_connectedness = social_connectedness[social_connectedness['log_sci'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip1</th>\n",
       "      <th>zip2</th>\n",
       "      <th>scaled_sci</th>\n",
       "      <th>log_sci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11200201</th>\n",
       "      <td>53104</td>\n",
       "      <td>01431</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11200202</th>\n",
       "      <td>53104</td>\n",
       "      <td>01432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11200203</th>\n",
       "      <td>53104</td>\n",
       "      <td>01434</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11200206</th>\n",
       "      <td>53104</td>\n",
       "      <td>01450</td>\n",
       "      <td>4670</td>\n",
       "      <td>8.449128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11200210</th>\n",
       "      <td>53104</td>\n",
       "      <td>01460</td>\n",
       "      <td>2041</td>\n",
       "      <td>7.621685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582697</th>\n",
       "      <td>93591</td>\n",
       "      <td>93550</td>\n",
       "      <td>1399346</td>\n",
       "      <td>14.151516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582698</th>\n",
       "      <td>93591</td>\n",
       "      <td>93551</td>\n",
       "      <td>1163304</td>\n",
       "      <td>13.966776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582699</th>\n",
       "      <td>93591</td>\n",
       "      <td>93552</td>\n",
       "      <td>1693713</td>\n",
       "      <td>14.342434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582700</th>\n",
       "      <td>93591</td>\n",
       "      <td>93553</td>\n",
       "      <td>3493403</td>\n",
       "      <td>15.066387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582704</th>\n",
       "      <td>93591</td>\n",
       "      <td>93591</td>\n",
       "      <td>10373190</td>\n",
       "      <td>16.154735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4866436 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           zip1   zip2  scaled_sci    log_sci\n",
       "11200201  53104  01431           1   0.693147\n",
       "11200202  53104  01432           1   0.693147\n",
       "11200203  53104  01434           1   0.693147\n",
       "11200206  53104  01450        4670   8.449128\n",
       "11200210  53104  01460        2041   7.621685\n",
       "...         ...    ...         ...        ...\n",
       "16582697  93591  93550     1399346  14.151516\n",
       "16582698  93591  93551     1163304  13.966776\n",
       "16582699  93591  93552     1693713  14.342434\n",
       "16582700  93591  93553     3493403  15.066387\n",
       "16582704  93591  93591    10373190  16.154735\n",
       "\n",
       "[4866436 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_connectedness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gravity Model Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\" Calculate the great circle distance between two points. More accurate than euclidean distance for Earth locations.\"\"\"\n",
    "    R = 6371  # Earth's radius in kilometers\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(dlat / 2) * math.sin(dlat / 2) +\n",
    "         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *\n",
    "         math.sin(dlon / 2) * math.sin(dlon / 2))\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def load_zipcode_coordinates(url):\n",
    "    df = pd.read_csv(url)\n",
    "    df['ZIP'] = df['ZIP'].astype(str).str.zfill(5)\n",
    "    return {row.ZIP: (row.LAT, row.LNG) for _, row in df.iterrows()}\n",
    "\n",
    "url = \"https://gist.githubusercontent.com/erichurst/7882666/raw/5bdc46db47d9515269ab12ed6fb2850377fd869e/US%2520Zip%2520Codes%2520from%25202013%2520Government%2520Data\"\n",
    "zipcode_coordinates = load_zipcode_coordinates(url)\n",
    "\n",
    "\n",
    "# Calculate distances\n",
    "zip_to_zip_distance = []\n",
    "for zip1, zip2 in social_connectedness[['zip1','zip2']].itertuples(index=False):\n",
    "    if zip1 is not np.nan and zip2 is not np.nan:\n",
    "        distance = haversine_distance(zipcode_coordinates[zip1][0], zipcode_coordinates[zip1][1], zipcode_coordinates[zip2][0], zipcode_coordinates[zip2][1])\n",
    "        zip_to_zip_distance.append([zip1, zip2, distance])\n",
    "\n",
    "zip_to_zip_distance_df = pd.DataFrame(zip_to_zip_distance, columns=['zip1', 'zip2', 'distance'])\n",
    "zip_to_zip_distance_df['gravity'] = zip_to_zip_distance_df['distance']**(-2)\n",
    "zip_to_zip_distance_df['gravity1.5'] = zip_to_zip_distance_df['distance']**(-1.5)\n",
    "zip_to_zip_distance_df['gravity1'] = zip_to_zip_distance_df['distance']**(-1)\n",
    "social_connectedness_distance = social_connectedness.merge(zip_to_zip_distance_df, left_on=['zip1', 'zip2'], right_on=['zip1', 'zip2'], how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Gravity + FB SCI w/ Cuebiq PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_social_connectedness_overlap = {}\n",
    "for regioncode, zip_to_zip_overlap_means_df in zip2zipPIS.items():\n",
    "    # Join dataframes\n",
    "    social_connectedness_overlap = social_connectedness_distance.merge(zip_to_zip_overlap_means_df, left_on=['zip1', 'zip2'], right_on=['zip1', 'zip2'], how='right')\n",
    "\n",
    "    all_social_connectedness_overlap[regioncode] = social_connectedness_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4866436, [39060, 463203, 68635, 80200, 37675])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(social_connectedness), [len(sc) for sc in all_social_connectedness_overlap.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39060, 463203, 68635, 80200, 37675]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(sc) for sc in zip2zipPIS.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check\n",
    "# for regioncode, social_connectedness_overlap in all_social_connectedness_overlap.items():\n",
    "#     print(regioncode)\n",
    "#     plt.imshow(social_connectedness_overlap.corr('pearson'))\n",
    "#     plt.show()\n",
    "\n",
    "#     social_connectedness_overlap.plot.scatter('log_geohash7', 'log_sci', alpha=0.7, s=1)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for regioncode, social_connectedness_overlap in all_social_connectedness_overlap.items():\n",
    "    social_connectedness_overlap.to_csv(f'results/all_PSI_SCI_gravity_{regioncode}.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
